<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>CSHybridEndpointAnalyzer.h</title>
    <meta name="viewport" content="width=device-width">
    <style>
    body { margin: 1em; }
    pre { font: 11pt/1.25 ui-monospace, "SF Mono", Menlo, monospace; }
    a { color: #af52de; }
    pre { white-space: pre-wrap; }
    header, footer { color: #8e8e93; }
    header { white-space: pre; }
    footer { max-width: 700px; }
    hr { border: 0; border-top: 1px solid #c6c6c8; }
    .download { text-decoration: none; }
    @media (prefers-color-scheme: dark) {
        body { background: black; color: white; }
        a { color: #bf5af2; }
        hr { border-top-color: #333335; }
    }
    </style>
</head>
<body>
<pre><header>
 ___          _   _             ___
| _ \_  _ _ _| |_(_)_ __  ___  | _ )_ _ _____ __ _____ ___ _ _
|   / || | ' \  _| | '  \/ -_) | _ \ '_/ _ \ V  V (_-// -_) '_|
|_|_\\_,_|_||_\__|_|_|_|_\___| |___/_| \___/\_/\_//__/\___|_|


</header><hr>

/PrivateFrameworks/CoreSpeech.framework/CSHybridEndpointAnalyzer.h <a href="?download" download title="Download" class="download">&darr;</a>


/* Generated by RuntimeBrowser
   Platform: iOS 12.5.7 (16H81) arm64
   Image: /System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech ()
 */

@interface CSHybridEndpointAnalyzer : NSObject <CSAssetManagerDelegate, CSEndpointAnalyzerImpl, EARCaesuraSilencePosteriorGeneratorDelegate> {
    unsigned long long  _activeChannel;
    NSObject<OS_dispatch_queue> * _apQueue;
    double  _automaticEndpointingSuspensionEndTime;
    EARCaesuraSilencePosteriorGenerator * _caesuraSPG;
    bool  _canProcessCurrentRequest;
    double  _clampedSFLatencyMsForClientLag;
    double  _clientLagThresholdMs;
    EARClientSilenceFeatures * _clientSilenceFeaturesAtEndpoint;
    CSAsset * _currentAsset;
    unsigned long long  _currentRequestSampleRate;
    double  _delay;
    <CSEndpointAnalyzerDelegate> * _delegate;
    bool  _didAddAudio;
    bool  _didCommunicateEndpoint;
    bool  _didDetectSpeech;
    bool  _didReceiveServerFeatures;
    bool  _didTimestampFirstAudioPacket;
    double  _elapsedTimeWithNoSpeech;
    double  _endWaitTime;
    long long  _endpointMode;
    long long  _endpointStyle;
    NSString * _endpointerModelVersion;
    NSDate * _firstAudioPacketTimestamp;
    double  _hepAudioOriginInMs;
    _EAREndpointer * _hybridClassifier;
    NSObject<OS_dispatch_queue> * _hybridClassifierQueue;
    double  _interspeechWaitTime;
    CSServerEndpointFeatures * _lastKnownServerEPFeatures;
    double  _lastReportedEndpointTimeMs;
    NSDate * _lastServerFeatureTimestamp;
    double  _minimumDurationForEndpointer;
    unsigned long long  _numSamplesProcessed;
    NSDictionary * _recordContext;
    bool  _recordingDidStop;
    bool  _saveSamplesSeenInReset;
    NSMutableArray * _serverFeatureLatencies;
    NSObject<OS_dispatch_queue> * _serverFeaturesQueue;
    double  _serverFeaturesWarmupLatency;
    NSObject<OS_dispatch_queue> * _silencePosteriorGeneratorQueue;
    double  _startWaitTime;
    NSObject<OS_dispatch_queue> * _stateSerialQueue;
    double  _trailingSilenceDurationAtEndpoint;
    bool  _useDefaultServerFeaturesOnClientLag;
    unsigned long long  _vtEndInSampleCount;
    double  _vtExtraAudioAtStartInMs;
}

@property (nonatomic) unsigned long long activeChannel;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *apQueue;
@property (nonatomic) double automaticEndpointingSuspensionEndTime;
@property (nonatomic) double bypassSamples;
@property (nonatomic, retain) EARCaesuraSilencePosteriorGenerator *caesuraSPG;
@property (nonatomic) bool canProcessCurrentRequest;
@property (nonatomic) double clampedSFLatencyMsForClientLag;
@property (nonatomic) double clientLagThresholdMs;
@property (nonatomic, retain) EARClientSilenceFeatures *clientSilenceFeaturesAtEndpoint;
@property (nonatomic, retain) CSAsset *currentAsset;
@property (nonatomic) unsigned long long currentRequestSampleRate;
@property (readonly, copy) NSString *debugDescription;
@property (nonatomic) double delay;
@property (nonatomic) <CSEndpointAnalyzerDelegate> *delegate;
@property (readonly, copy) NSString *description;
@property (nonatomic) bool didAddAudio;
@property (nonatomic) bool didCommunicateEndpoint;
@property (nonatomic) bool didDetectSpeech;
@property (nonatomic) bool didReceiveServerFeatures;
@property (nonatomic) bool didTimestampFirstAudioPacket;
@property (nonatomic) double elapsedTimeWithNoSpeech;
@property (nonatomic) double endWaitTime;
@property (nonatomic) long long endpointMode;
@property (nonatomic) long long endpointStyle;
@property (nonatomic, retain) NSString *endpointerModelVersion;
@property (nonatomic, retain) NSDate *firstAudioPacketTimestamp;
@property (readonly) unsigned long long hash;
@property (nonatomic) double hepAudioOriginInMs;
@property (nonatomic, retain) _EAREndpointer *hybridClassifier;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *hybridClassifierQueue;
@property (nonatomic) double interspeechWaitTime;
@property (nonatomic, readonly) double lastEndOfVoiceActivityTime;
@property (nonatomic, retain) CSServerEndpointFeatures *lastKnownServerEPFeatures;
@property (nonatomic) double lastReportedEndpointTimeMs;
@property (nonatomic, retain) NSDate *lastServerFeatureTimestamp;
@property (nonatomic, readonly) double lastStartOfVoiceActivityTime;
@property (nonatomic) double minimumDurationForEndpointer;
@property (nonatomic) unsigned long long numSamplesProcessed;
@property (nonatomic, retain) NSDictionary *recordContext;
@property (nonatomic) bool recordingDidStop;
@property (nonatomic) bool saveSamplesSeenInReset;
@property (nonatomic, retain) NSMutableArray *serverFeatureLatencies;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *serverFeaturesQueue;
@property (nonatomic) double serverFeaturesWarmupLatency;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *silencePosteriorGeneratorQueue;
@property (nonatomic) double startWaitTime;
@property (nonatomic, retain) NSObject<OS_dispatch_queue> *stateSerialQueue;
@property (readonly) Class superclass;
@property (nonatomic) double trailingSilenceDurationAtEndpoint;
@property (nonatomic) bool useDefaultServerFeaturesOnClientLag;
@property (nonatomic) unsigned long long vtEndInSampleCount;
@property (nonatomic) double vtExtraAudioAtStartInMs;

- (void).cxx_destruct;
- (void)CSAssetManagerDidDownloadNewAsset:(id)arg1;
- (void)CSLanguageCodeUpdateMonitor:(id)arg1 didReceiveLanguageCodeChanged:(id)arg2;
- (id)_getCSHybridEndpointerConfigForAsset:(id)arg1;
- (void)_readClientLagParametersFromHEPAsset:(id)arg1;
- (void)_updateAssetWithCurrentLanguage;
- (void)_updateAssetWithLanguage:(id)arg1;
- (unsigned long long)activeChannel;
- (id)apQueue;
- (double)automaticEndpointingSuspensionEndTime;
- (id)caesuraSPG;
- (bool)canProcessCurrentRequest;
- (double)clampedSFLatencyMsForClientLag;
- (double)clientLagThresholdMs;
- (id)clientSilenceFeaturesAtEndpoint;
- (void)clientSilenceFeaturesAvailable:(id)arg1;
- (id)currentAsset;
- (unsigned long long)currentRequestSampleRate;
- (double)delay;
- (id)delegate;
- (bool)didAddAudio;
- (bool)didCommunicateEndpoint;
- (bool)didDetectSpeech;
- (bool)didReceiveServerFeatures;
- (bool)didTimestampFirstAudioPacket;
- (double)elapsedTimeWithNoSpeech;
- (double)endWaitTime;
- (long long)endpointMode;
- (long long)endpointStyle;
- (id)endpointerModelVersion;
- (id)firstAudioPacketTimestamp;
- (void)handleVoiceTriggerWithActivationInfo:(id)arg1;
- (double)hepAudioOriginInMs;
- (id)hybridClassifier;
- (id)hybridClassifierQueue;
- (id)init;
- (double)interspeechWaitTime;
- (double)lastEndOfVoiceActivityTime;
- (id)lastKnownServerEPFeatures;
- (double)lastReportedEndpointTimeMs;
- (id)lastServerFeatureTimestamp;
- (double)lastStartOfVoiceActivityTime;
- (double)minimumDurationForEndpointer;
- (unsigned long long)numSamplesProcessed;
- (void)preheat;
- (void)processAudioSamplesAsynchronously:(id)arg1;
- (void)processServerEndpointFeatures:(id)arg1;
- (id)recordContext;
- (bool)recordingDidStop;
- (void)recordingStoppedForReason:(unsigned long long)arg1;
- (void)reset;
- (void)resetForNewRequestWithSampleRate:(unsigned long long)arg1 recordContext:(id)arg2;
- (bool)saveSamplesSeenInReset;
- (id)serverFeatureLatencies;
- (id)serverFeaturesLatencyDistributionDictionary;
- (id)serverFeaturesQueue;
- (double)serverFeaturesWarmupLatency;
- (void)setActiveChannel:(unsigned long long)arg1;
- (void)setApQueue:(id)arg1;
- (void)setAutomaticEndpointingSuspensionEndTime:(double)arg1;
- (void)setCaesuraSPG:(id)arg1;
- (void)setCanProcessCurrentRequest:(bool)arg1;
- (void)setClampedSFLatencyMsForClientLag:(double)arg1;
- (void)setClientLagThresholdMs:(double)arg1;
- (void)setClientSilenceFeaturesAtEndpoint:(id)arg1;
- (void)setCurrentAsset:(id)arg1;
- (void)setCurrentRequestSampleRate:(unsigned long long)arg1;
- (void)setDelay:(double)arg1;
- (void)setDelegate:(id)arg1;
- (void)setDidAddAudio:(bool)arg1;
- (void)setDidCommunicateEndpoint:(bool)arg1;
- (void)setDidDetectSpeech:(bool)arg1;
- (void)setDidReceiveServerFeatures:(bool)arg1;
- (void)setDidTimestampFirstAudioPacket:(bool)arg1;
- (void)setElapsedTimeWithNoSpeech:(double)arg1;
- (void)setEndWaitTime:(double)arg1;
- (void)setEndpointMode:(long long)arg1;
- (void)setEndpointStyle:(long long)arg1;
- (void)setEndpointerModelVersion:(id)arg1;
- (void)setFirstAudioPacketTimestamp:(id)arg1;
- (void)setHepAudioOriginInMs:(double)arg1;
- (void)setHybridClassifier:(id)arg1;
- (void)setHybridClassifierQueue:(id)arg1;
- (void)setInterspeechWaitTime:(double)arg1;
- (void)setLastKnownServerEPFeatures:(id)arg1;
- (void)setLastReportedEndpointTimeMs:(double)arg1;
- (void)setLastServerFeatureTimestamp:(id)arg1;
- (void)setMinimumDurationForEndpointer:(double)arg1;
- (void)setNumSamplesProcessed:(unsigned long long)arg1;
- (void)setRecordContext:(id)arg1;
- (void)setRecordingDidStop:(bool)arg1;
- (void)setSaveSamplesSeenInReset:(bool)arg1;
- (void)setServerFeatureLatencies:(id)arg1;
- (void)setServerFeaturesQueue:(id)arg1;
- (void)setServerFeaturesWarmupLatency:(double)arg1;
- (void)setSilencePosteriorGeneratorQueue:(id)arg1;
- (void)setStartWaitTime:(double)arg1;
- (void)setStateSerialQueue:(id)arg1;
- (void)setTrailingSilenceDurationAtEndpoint:(double)arg1;
- (void)setUseDefaultServerFeaturesOnClientLag:(bool)arg1;
- (void)setVtEndInSampleCount:(unsigned long long)arg1;
- (void)setVtExtraAudioAtStartInMs:(double)arg1;
- (void)shouldAcceptEagerResultForDuration:(double)arg1 resultsCompletionHandler:(id /* block */)arg2;
- (id)silencePosteriorGeneratorQueue;
- (double)startWaitTime;
- (id)stateSerialQueue;
- (double)trailingSilenceDurationAtEndpoint;
- (void)updateEndpointerDelayedTrigger:(bool)arg1;
- (void)updateEndpointerThreshold:(float)arg1;
- (bool)useDefaultServerFeaturesOnClientLag;
- (unsigned long long)vtEndInSampleCount;
- (double)vtExtraAudioAtStartInMs;

@end


<hr><footer>
Source code: <a href="https://github.com/hbang/RuntimeBrowser">https://github.com/hbang/RuntimeBrowser</a>

Authors:
  Ezra Epstein (eepstein@prajna.com)
  Nicolas Seriot (nicolas@seriot.ch)
  HASHBANG Productions

Copyright &copy; 2002 by Prajna IT Consulting
Copyright &copy; 2015 by <a href="http://www.seriot.ch">Nicolas Seriot</a>
Copyright &copy; 2021 by <a href="https://hashbang.productions">HASHBANG Productions</a>

THIS PROGRAM AND THIS CODE COME WITH ABSOLUTELY NO WARRANTY. THIS CODE HAS BEEN PROVIDED "AS IS" AND THE RESPONSIBILITY FOR ITS OPERATIONS IS 100% YOURS.

RuntimeBrowser is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.

RuntimeBrowser is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with RuntimeBrowser (in a file called "COPYING.txt"); if not, write to the Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA</footer></pre>
</body>
</html>
